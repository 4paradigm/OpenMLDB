# my global config
global:
  scrape_interval: 1m # Set the scrape interval, default is every 1 minute.
  evaluation_interval: 1m # Evaluate rules, default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: prometheus
    static_configs:
      - targets:
        - localhost:9090

  - job_name: node
    # the job pull machine & OS related metrics, which exported by prometheus node_exporter
    # refer https://github.com/prometheus/node_exporter for instructions and setup

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
      - targets:
        - 172.17.0.15:9100

  - job_name: openmldb_components
    # job to pull component metrics from OpenMLDB like tablet/nameserver
    # tweak the 'targets' list in 'static_configs' on your need
    # every nameserver/tablet component endpoint should be added into targets
    metrics_path: /brpc_metrics
    static_configs:
      - targets:
        - 172.17.0.15:9622

  - job_name: openmldb_exporter
    # pull OpenMLDB DB-Level specific metric
    # change the 'targets' value to your deployed OpenMLDB exporter endpoint
    static_configs:
      - targets:
        - 172.17.0.15:8000
